{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2c174a9-498c-428d-a25e-cdcdec6990c0",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sys.path.append('..')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "af6b9731-5eea-456a-8e32-42b41b369bb2",
   "metadata": {},
   "source": [
    "# Read in ChargePoint/ViriCiti data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f12d272a-ce57-40e2-bc02-ff346b8cae42",
   "metadata": {},
   "source": [
    "vc_file = '../beb_chargers/data/viriciti/mar24_energy_data.csv'\n",
    "vc_df = pd.read_csv(vc_file)\n",
    "vc_df = vc_df.astype(\n",
    "    dtype={\n",
    "        'Name': str,\n",
    "        'ISO Time': str\n",
    "    }\n",
    ")\n",
    "# Convert time column to datetime and make sure it's the right time zone\n",
    "vc_df['ISO Time'] = pd.to_datetime(vc_df['ISO Time'], utc=True).dt.tz_convert('US/Pacific')\n",
    "# Identify all vehicle IDs observed\n",
    "vids = vc_df['Name'].unique()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "08918137-7923-4e41-9cdb-10482e005bf5",
   "metadata": {},
   "source": [
    "# Read in GTFS-realtime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "579ebf56-c937-4298-88a9-c8c89c182674",
   "metadata": {},
   "source": [
    "rt_prefix = '../beb_chargers/data/realtime/metro'\n",
    "rt_files = sorted([f for f in os.listdir(rt_prefix) if f[-4:]=='.pkl'])\n",
    "df_list = list()\n",
    "for f in rt_files:\n",
    "    fname = rt_prefix + '/' + f\n",
    "    # Read in realtime data provided by Zack\n",
    "    df = pd.read_pickle(fname).reset_index(drop=True)\n",
    "    df = df.astype(\n",
    "        dtype={\n",
    "            'vehicle_id': str,\n",
    "            'scheduleDeviation': int,\n",
    "            'trip_id': str\n",
    "        }\n",
    "    )\n",
    "    # Convert time column to datetime and change time zone\n",
    "    df['locationtime'] = pd.to_datetime(\n",
    "        df['locationtime'].astype(int), unit='s', utc=True).dt.tz_convert('US/Pacific')\n",
    "    \n",
    "    # Filter down realtime data to only include buses in ChargePoint data\n",
    "    df = df[df['vehicle_id'].isin(vids)]\n",
    "    df = df.drop(columns=['orientation'])\n",
    "    df_list.append(df)\n",
    "rt_df = pd.concat(df_list).reset_index()\n",
    "# Add a date column for grouping data by day\n",
    "rt_df['date'] = pd.to_datetime(rt_df['locationtime'].dt.date)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fba82573-4970-4e09-9c56-653e6d23ad18",
   "metadata": {},
   "source": [
    "# Read in static GTFS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "707b15c1-68fb-44b0-b4b4-d03283ecd695",
   "metadata": {},
   "source": [
    "# Read in GTFS stop times\n",
    "stop_times_df = pd.read_csv('../beb_chargers/data/gtfs/metro_mar24/stop_times.txt')\n",
    "stop_times_df = stop_times_df.astype(\n",
    "    {'trip_id': str, 'stop_id': str}\n",
    ")\n",
    "# Filter down to included trip IDs\n",
    "stop_times_df = stop_times_df[stop_times_df['trip_id'].isin(rt_df['trip_id'].unique())]\n",
    "# Convert to timedeltas\n",
    "stop_times_df['departure_timedelta'] = pd.to_timedelta(stop_times_df['departure_time'])\n",
    "\n",
    "# Trips file (gives us shape and route IDs)\n",
    "trips_df = pd.read_csv('../beb_chargers/data/gtfs/metro_mar24/trips.txt')\n",
    "trips_df = trips_df.astype(\n",
    "    {'trip_id': str, 'shape_id': str, 'route_id': str}\n",
    ")\n",
    "trips_df = trips_df[trips_df['trip_id'].isin(rt_df['trip_id'].unique())]\n",
    "\n",
    "# Routes file (gives us route names)\n",
    "routes_df = pd.read_csv('../beb_chargers/data/gtfs/metro_mar24/routes.txt')\n",
    "routes_df = routes_df.astype(\n",
    "    {'route_id': str}\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3958aa25-3a2b-46b2-9c7c-d137aa0d7cfd",
   "metadata": {},
   "source": [
    "# Add stop info to realtime\n",
    "rt_df = rt_df.merge(\n",
    "    stop_times_df.drop(\n",
    "        columns=[\n",
    "            'arrival_time', 'departure_time', 'stop_headsign', 'pickup_type', 'drop_off_type', 'shape_dist_traveled', 'timepoint']\n",
    "    ),\n",
    "    left_on=['trip_id', 'nextStop'], right_on=['trip_id', 'stop_id']\n",
    ")\n",
    "rt_df['departure_time'] = (rt_df['date'] + rt_df['departure_timedelta']).dt.tz_localize('US/Pacific')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7f61e40c-83f1-4141-a43e-9beb449ded86",
   "metadata": {},
   "source": [
    "# Clean realtime data\n",
    "Remove outliers and identify start/end times of all trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1eda922-99e2-4019-b89b-4d8602e4edf2",
   "metadata": {},
   "source": [
    "clean_count = 0\n",
    "error_count = 0\n",
    "plot_ix = 0\n",
    "dates = list()\n",
    "tids = list()\n",
    "start_times = list()\n",
    "end_times = list()\n",
    "start_delays = list()\n",
    "end_delays = list()\n",
    "veh_ids = list()\n",
    "sort_by = 'locationtime'  # ['stop_sequence', 'locationtime']\n",
    "all_dates = rt_df['date'].unique()\n",
    "error_dfs = list()\n",
    "for d in all_dates:\n",
    "    d_df = rt_df[rt_df['date'] == d]\n",
    "    all_trips = d_df['trip_id'].unique()\n",
    "    for t in all_trips:\n",
    "        t_df = d_df[d_df['trip_id'] == t].sort_values(by=sort_by)\n",
    "\n",
    "        # Exclude temporal outliers with interquantile filter\n",
    "        q1 = t_df['locationtime'].quantile(.25)\n",
    "        q3 = t_df['locationtime'].quantile(.75)\n",
    "        iqr = q3 - q1\n",
    "        t_df = t_df[\n",
    "            t_df['locationtime'].between(\n",
    "                q1-0.75*iqr,\n",
    "                q3+0.75*iqr\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Another IQR filter for schedule deviation\n",
    "        q1 = t_df['scheduleDeviation'].quantile(.25)\n",
    "        q3 = t_df['scheduleDeviation'].quantile(.75)\n",
    "        iqr = q3 - q1\n",
    "        t_df = t_df[\n",
    "            t_df['scheduleDeviation'].between(\n",
    "                q1 - 1.5*iqr,\n",
    "                q3 + 1.5*iqr\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        # Exclude all data that includes big negative schedule deviations\n",
    "        t_df = t_df[t_df['scheduleDeviation'] > -900]\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            t_df = t_df.sort_values(by=['stop_sequence', 'locationtime'])\n",
    "            first_stop_df = t_df.groupby('nextStop').tail(1).iloc[0]\n",
    "            first_stop_delay = first_stop_df['scheduleDeviation']\n",
    "            first_recorded_time = first_stop_df['locationtime']\n",
    "            veh_id = first_stop_df['vehicle_id']\n",
    "            last_recorded_time = t_df.groupby('nextStop').head(1).iloc[-1]['locationtime']\n",
    "            last_stop_delay = t_df.groupby('nextStop').head(1).iloc[-1]['scheduleDeviation']\n",
    "            \n",
    "            start_times.append(first_recorded_time)\n",
    "            end_times.append(last_recorded_time)\n",
    "            start_delays.append(first_stop_delay)\n",
    "            end_delays.append(last_stop_delay)\n",
    "            veh_ids.append(veh_id)\n",
    "            tids.append(t)\n",
    "            dates.append(d)\n",
    "            clean_count += 1\n",
    "            \n",
    "        except IndexError as e:\n",
    "            error_count += 1\n",
    "            # We end up here if the DF is empty after filtering\n",
    "            t_df = d_df[d_df['trip_id'] == t].sort_values(by='locationtime')\n",
    "            error_dfs.append(t_df)\n",
    "            fig = px.line(t_df, x='locationtime', y='scheduleDeviation', title='{}, Trip {}'.format(\n",
    "                datetime.datetime.strftime(d, '%m/%d/%Y'), t))\n",
    "            fig.write_image('images/error_delay_by_trip_{}.pdf'.format(plot_ix))\n",
    "            plot_ix += 1\n",
    "\n",
    "rt_trip_summary = pd.DataFrame(\n",
    "    {\n",
    "        'date': dates,\n",
    "        'vehicle_id': veh_ids,\n",
    "        'trip_id': tids,\n",
    "        'first_recorded_time': start_times,\n",
    "        'last_recorded_time': end_times,\n",
    "        'delay_at_start': start_delays,\n",
    "        'delay_at_end': end_delays\n",
    "    }\n",
    ").sort_values(by=['vehicle_id', 'first_recorded_time'])\n",
    "print(error_count, clean_count)\n",
    "\n",
    "# Only include trips at least 10 minutes long\n",
    "rt_trip_summary['recorded_duration'] = rt_trip_summary['last_recorded_time'] - rt_trip_summary['first_recorded_time']\n",
    "rt_trip_summary = rt_trip_summary[rt_trip_summary['recorded_duration'].dt.total_seconds() > 600]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13514416-267a-4b4d-b11f-ccf42478813d",
   "metadata": {},
   "source": [
    "rt_trip_summary['first_recorded_time'].dt.hour.value_counts().sort_index()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0c72ac2e-23f7-482c-a7d4-948725ede335",
   "metadata": {},
   "source": [
    "## Filter down the data to exclude any points outside the recorded bounds\n",
    "We don't really use the raw data any further, so this is a bit unnecessary, but validates our approach above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "346de2c8-0776-40c4-a860-c84fde15fdf3",
   "metadata": {},
   "source": [
    "def get_trip_realtime(realtime_df, tid, min_time=None, max_time=None):\n",
    "    \"\"\"\n",
    "    Get the realtime data associated with the given vehicle ID\n",
    "    within the time range [min_time, max_time].\n",
    "    \"\"\"\n",
    "    t_df = realtime_df[realtime_df['trip_id'] == tid]\n",
    "    if min_time is not None:\n",
    "        t_df = t_df[t_df['locationtime'] >= min_time]\n",
    "    if max_time is not None:\n",
    "        t_df = t_df[t_df['locationtime'] <= max_time]\n",
    "\n",
    "    return t_df.sort_values(by='locationtime')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f514a77b-87d9-4904-9926-8501d698be7f",
   "metadata": {},
   "source": [
    "# This code is clunky and slow, but gets the job done\n",
    "trip_dfs = list()\n",
    "trip_summary = rt_trip_summary.set_index(['date', 'trip_id'])\n",
    "for ix in trip_summary.index:\n",
    "    t_df = get_trip_realtime(rt_df, ix[1], trip_summary.loc[ix, 'first_recorded_time'], trip_summary.loc[ix, 'last_recorded_time'])\n",
    "    # Run IQR filter again on cleaned data\n",
    "    q1 = t_df['locationtime'].quantile(.25)\n",
    "    q3 = t_df['locationtime'].quantile(.75)\n",
    "    iqr = q3 - q1\n",
    "    t_df = t_df[\n",
    "        t_df['locationtime'].between(\n",
    "            q1-0.75*iqr,\n",
    "            q3+0.75*iqr\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    trip_dfs.append(t_df)\n",
    "rt_cleaned = pd.concat(trip_dfs).sort_values(by='locationtime')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c68267d0-2191-442c-8a0a-58df95aad308",
   "metadata": {},
   "source": [
    "len(rt_df), len(rt_cleaned)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9f48acb5-b2a3-46b3-beea-0a143c8f970d",
   "metadata": {},
   "source": [
    "# Visualize the results of data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0199d2d9-fa89-4f7d-9cd1-7ef76d802853",
   "metadata": {},
   "source": [
    "## Show some problematic data prior to cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f370f48a-f81c-491c-ad46-4931cdb00d16",
   "metadata": {},
   "source": [
    "n = 0\n",
    "bad_vehs = rt_df.set_index(['date', 'trip_id']).reset_index()[['date', 'vehicle_id']].drop_duplicates()\n",
    "for ix, rw in bad_vehs.iterrows():\n",
    "    n += 1\n",
    "    # n > 20\n",
    "    if n > 5:\n",
    "        break\n",
    "    veh_df = rt_df[\n",
    "        (rt_df['date'] == rw['date']) & (rt_df['vehicle_id'] == rw['vehicle_id'])\n",
    "    ]\n",
    "    fig = px.scatter(\n",
    "        veh_df, x='locationtime', y='scheduleDeviation', color='trip_id'\n",
    "    )\n",
    "    date_str = rw.date.strftime('%-m/%-d/%Y')\n",
    "    fig.update_layout(\n",
    "        title_text=f'Bus {rw.vehicle_id} on {date_str}'\n",
    "    )\n",
    "    if rw['vehicle_id'] == '4712' and rw['date'] == datetime.datetime(2024, 3, 3):\n",
    "        fig.write_image('raw_4712.pdf')\n",
    "\n",
    "    fig.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c6462c5-2630-4d75-8a3a-ee4dd9238412",
   "metadata": {},
   "source": [
    "veh_df = rt_df[\n",
    "    (rt_df['date'] == '03-03-2024') & (rt_df['vehicle_id'] == '4712')\n",
    "]\n",
    "# veh_df = veh_df[veh_df['locationtime'] <= '2024-03-01 08:18:43-08:00']\n",
    "fig = px.scatter(\n",
    "        veh_df, x='locationtime', y='scheduleDeviation', color='trip_id'\n",
    "    )\n",
    "date_str = '3/3/2024'\n",
    "# date_str = rw.date.strftime('%-m/%-d/%Y')\n",
    "fig.update_layout(\n",
    "    title_text=f'Bus 4712 on {date_str}',\n",
    "    legend_title_text='Trip ID'\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image('rt_trip_id_problem.pdf')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e607901a-7a86-48fa-8ea4-2405255ac362",
   "metadata": {},
   "source": [
    "## Show the different types of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d71986d9-2d5f-42f8-9253-e2721ea4673d",
   "metadata": {},
   "source": [
    "veh_df = rt_df[\n",
    "    (rt_df['date'] == '03-02-2024') & (rt_df['trip_id'] == '635411515')\n",
    "]\n",
    "veh_df = veh_df.copy()\n",
    "veh_df['Outlier Type'] = 'Not outlier'\n",
    "\n",
    "q1 = veh_df['scheduleDeviation'].quantile(0.25)\n",
    "q3 = veh_df['scheduleDeviation'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "veh_df.loc[~veh_df['scheduleDeviation'].between(q1 - 1.5*iqr, q3 + 1.5*iqr), 'Outlier Type'] = 'Schedule deviation'\n",
    "\n",
    "q1 = veh_df['locationtime'].quantile(0.25)\n",
    "q3 = veh_df['locationtime'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "veh_df.loc[~veh_df['locationtime'].between(q1 - 0.75*iqr, q3 + 0.75*iqr), 'Outlier Type'] = 'Sample time'\n",
    "\n",
    "fig = px.scatter(\n",
    "    veh_df, x='locationtime', y='scheduleDeviation', color='Outlier Type'\n",
    ")\n",
    "date_str = '3/2/2024'\n",
    "# date_str = rw.date.strftime('%-m/%-d/%Y')\n",
    "fig.update_layout(\n",
    "    title_text=f'Bus 4800, Trip 635411515 on {date_str}'\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image('rt_outliers.pdf')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "741b27c8-eee9-4420-b0cc-cfe31d368356",
   "metadata": {},
   "source": [
    "## Show the data after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "217d33d3-df6f-48cb-bfba-73706c2d73b1",
   "metadata": {},
   "source": [
    "veh_df = rt_cleaned[\n",
    "    (rt_cleaned['date'] == '03-03-2024') & (rt_cleaned['vehicle_id'] == '4712')\n",
    "]\n",
    "# veh_df = veh_df[veh_df['locationtime'] <= '2024-03-01 08:18:43-08:00']\n",
    "fig = px.scatter(\n",
    "        veh_df, x='locationtime', y='scheduleDeviation', color='trip_id'\n",
    "    )\n",
    "date_str = '3/3/2024'\n",
    "fig.update_layout(\n",
    "    title_text=f'Bus 4712 on {date_str}',\n",
    "    legend_title_text='Trip ID'\n",
    ")\n",
    "fig.show()\n",
    "fig.write_image('rt_trip_id_after_clean.pdf')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20f3a1a0-943e-42da-bea2-dd29e1a01c42",
   "metadata": {},
   "source": [
    "n = 0\n",
    "# bad_vehs = rt_cleaned.set_index(['date', 'trip_id']).loc[bad_ixs, :].reset_index()[['date', 'vehicle_id']].drop_duplicates()\n",
    "for ix, rw in bad_vehs.iterrows():\n",
    "    n += 1\n",
    "    if n > 5:\n",
    "        break\n",
    "    veh_df = rt_cleaned[\n",
    "        (rt_cleaned['date'] == rw['date']) & (rt_cleaned['vehicle_id'] == rw['vehicle_id'])\n",
    "    ]\n",
    "    fig = px.scatter(\n",
    "        veh_df, x='locationtime', y='scheduleDeviation', color='trip_id'\n",
    "    )\n",
    "    date_str = rw.date.strftime('%-m/%-d/%Y')\n",
    "    fig.update_layout(\n",
    "        title_text=f'Bus {rw.vehicle_id} on {date_str}'\n",
    "    )\n",
    "    if rw['vehicle_id'] == '4712' and rw['date'] == datetime.datetime(2024, 3, 3):\n",
    "        fig.write_image('cleaned_4712.pdf')\n",
    "    fig.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "61fc78aa-88b8-4cfc-9086-d2410e8cd37e",
   "metadata": {},
   "source": [
    "# Process realtime data to estimate trip durations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5608db-d9e9-4c36-9878-f57a9ccd16c3",
   "metadata": {},
   "source": [
    "## Summarize scheduled times from static GTFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f81d7e30-4e07-40c9-b238-b89d703a97cd",
   "metadata": {},
   "source": [
    "scheduled_times = pd.DataFrame()\n",
    "scheduled_times['start_time_sched'] = stop_times_df.sort_values(\n",
    "    by=['trip_id', 'departure_time']).groupby('trip_id')[\n",
    "['trip_id', 'departure_time']].head(1).set_index('trip_id')\n",
    "scheduled_times['end_time_sched'] = stop_times_df.sort_values(\n",
    "    by=['trip_id', 'departure_time']).groupby('trip_id')[\n",
    "['trip_id', 'departure_time']].tail(1).set_index('trip_id')\n",
    "scheduled_times['duration_sched'] = (\n",
    "    pd.to_timedelta(scheduled_times['end_time_sched']) - pd.to_timedelta(scheduled_times['start_time_sched'])\n",
    ").dt.total_seconds()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f593317e-84be-4e08-b6b7-db168b15420f",
   "metadata": {},
   "source": [
    "# Add scheduled duration column\n",
    "rt_trip_summary = rt_trip_summary.merge(\n",
    "    scheduled_times[['start_time_sched', 'end_time_sched', 'duration_sched']], \n",
    "    left_on='trip_id', right_index=True\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "788717f6-3d6e-42e0-95c4-dc2f1828127f",
   "metadata": {},
   "source": [
    "rt_trip_summary['start_time_sched'] = rt_trip_summary['date'] + pd.to_timedelta(rt_trip_summary['start_time_sched'])\n",
    "rt_trip_summary['end_time_sched'] = rt_trip_summary['date'] + pd.to_timedelta(rt_trip_summary['end_time_sched'])\n",
    "rt_trip_summary['start_time_actual'] = rt_trip_summary['start_time_sched'] + pd.to_timedelta(\n",
    "    rt_trip_summary['delay_at_start'], unit='s'\n",
    ")\n",
    "rt_trip_summary['end_time_actual'] = rt_trip_summary['end_time_sched'] + pd.to_timedelta(\n",
    "    rt_trip_summary['delay_at_end'], unit='s'\n",
    ")\n",
    "rt_trip_summary['start_time_actual'] = rt_trip_summary['start_time_actual'].dt.tz_localize('US/Pacific')\n",
    "rt_trip_summary['end_time_actual'] = rt_trip_summary['end_time_actual'].dt.tz_localize('US/Pacific')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c3df238-0802-4902-af80-5a6ad101340d",
   "metadata": {},
   "source": [
    "rt_trip_summary['time_difference'] = rt_trip_summary['delay_at_end'] - rt_trip_summary['delay_at_start']\n",
    "rt_trip_summary['duration_rt'] = rt_trip_summary['time_difference'] + rt_trip_summary['duration_sched']\n",
    "rt_trip_summary['time_difference_pct'] = 100 * rt_trip_summary['time_difference'] / rt_trip_summary['duration_sched']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "570537cd-4614-4413-93ab-96a0e9ccc2aa",
   "metadata": {},
   "source": [
    "rt_trip_summary['start_time_actual'].dt.hour.hist()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0a668c0e-bd28-4e51-823c-b873ed27a9aa",
   "metadata": {},
   "source": [
    "# Aggregate ChargePoint data to the trip level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccd72b88-6914-4c0d-b701-8815537a925b",
   "metadata": {},
   "source": [
    "# TODO: confusing code here, using both trip_times_df and rt_trip_summary\n",
    "trip_times_df = rt_trip_summary.set_index(['date', 'vehicle_id', 'trip_id'])\n",
    "vids = list()\n",
    "tids = list()\n",
    "kwhs = list()\n",
    "mis = list()\n",
    "cons = list()\n",
    "dates = list()\n",
    "n_samples = list()\n",
    "for (date, vid, tid) in trip_times_df.index:\n",
    "    # vid_times = trip_times_df.reset_index()\n",
    "    vid_times = rt_trip_summary[\n",
    "        (rt_trip_summary['vehicle_id'] == vid) & (rt_trip_summary['date'] == date)\n",
    "    ].set_index('trip_id')\n",
    "    vid_vc = vc_df[vc_df['Name'] == vid]\n",
    "\n",
    "    tid_df = vid_vc[vid_vc['ISO Time'].between(\n",
    "        vid_times.loc[tid, 'start_time_actual'],\n",
    "        vid_times.loc[tid, 'end_time_actual'],\n",
    "        inclusive='both'\n",
    "    )]\n",
    "    try:\n",
    "        # Filter out NAs\n",
    "        tid_full = tid_df[['ISO Time', 'Energy used (kWh)', 'Distance driven (mi)']].dropna().sort_values('ISO Time')\n",
    "        kwh_0 = tid_full.iloc[0]['Energy used (kWh)']\n",
    "        dist_0 = tid_full.iloc[0]['Distance driven (mi)']\n",
    "        kwh_end = tid_full.iloc[-1]['Energy used (kWh)']\n",
    "        dist_end = tid_full.iloc[-1]['Distance driven (mi)']\n",
    "        kwh_used = kwh_end - kwh_0\n",
    "        mi_driven = dist_end - dist_0\n",
    "        dates.append(date)\n",
    "        vids.append(vid)\n",
    "        tids.append(tid)\n",
    "        kwhs.append(kwh_used)\n",
    "        mis.append(mi_driven)\n",
    "        cons.append(kwh_used / mi_driven)\n",
    "        n_samples.append(len(tid_df))\n",
    "    except IndexError:\n",
    "        # We get here if every row has an NA value for either distance or kWh\n",
    "        pass"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3988bf38-1675-4552-ab64-ae189a5e8f09",
   "metadata": {},
   "source": [
    "vc_by_trip = pd.DataFrame(\n",
    "    data={\n",
    "        'date': dates,\n",
    "        'vehicle_id': vids,\n",
    "        'trip_id': tids,\n",
    "        'kwh': kwhs,\n",
    "        'miles': mis,\n",
    "        'kwh_per_mi': cons,\n",
    "        'n_samples': n_samples\n",
    "    }\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ab1a8fc6-1d77-416b-b852-4ba1ad338039",
   "metadata": {},
   "source": [
    "## Create an example plot of ChargePoint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93dbb71c-95ec-4a3f-8cd3-f90c1d23838c",
   "metadata": {},
   "source": [
    "date = datetime.datetime(2024, 3, 2)\n",
    "vid = '4800'\n",
    "tid = '635411515'\n",
    "vid_times = rt_trip_summary[\n",
    "    (rt_trip_summary['vehicle_id'] == vid) & (rt_trip_summary['date'] == date)\n",
    "].set_index('trip_id')\n",
    "\n",
    "vid_vc = vc_df[vc_df['Name'] == vid]\n",
    "tid_df = vid_vc[vid_vc['ISO Time'].between(\n",
    "    vid_times.loc[tid, 'start_time_actual'],\n",
    "    vid_times.loc[tid, 'end_time_actual'],\n",
    "    inclusive='both'\n",
    ")].copy()\n",
    "kwh_0 = tid_df.dropna().iloc[0]['Energy used (kWh)']\n",
    "dist_0 = tid_df.dropna().iloc[0]['Distance driven (mi)']\n",
    "tid_df['Energy used (kWh)'] = tid_df['Energy used (kWh)'] - kwh_0\n",
    "tid_df['Distance driven (mi)'] = tid_df['Distance driven (mi)'] - dist_0\n",
    "\n",
    "# Create figure with secondary y-axis\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Add traces\n",
    "secondary = [False, True]\n",
    "names = ['Energy', 'Distance']\n",
    "for ix, plot_col in enumerate(['Energy used (kWh)', 'Distance driven (mi)']):\n",
    "    fig.add_trace(go.Scatter(x=tid_df['ISO Time'], y=tid_df[plot_col], name=names[ix], mode='markers'), secondary_y=secondary[ix])\n",
    "\n",
    "# Add figure title\n",
    "fig.update_layout(\n",
    "    title_text='Bus 4800, Trip 635411515 on 3/2/2024'\n",
    ")\n",
    "\n",
    "# Set x-axis title\n",
    "fig.update_xaxes(title_text='Time')\n",
    "\n",
    "# Set y-axes titles\n",
    "fig.update_yaxes(title_text='Energy used (kWh)', secondary_y=False)\n",
    "fig.update_yaxes(title_text='Distance driven (mi)', secondary_y=True)\n",
    "\n",
    "fig.write_image('images/chargepoint_trip_example.pdf')\n",
    "fig.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a8c40ff-00d2-45e0-9c47-1a3d73d35fb9",
   "metadata": {},
   "source": [
    "date = datetime.datetime(2024, 3, 15)\n",
    "vid = '4714'\n",
    "tid = '635436455'\n",
    "vid_times = rt_trip_summary[\n",
    "    (rt_trip_summary['vehicle_id'] == vid) & (rt_trip_summary['date'] == date)\n",
    "].set_index('trip_id')\n",
    "\n",
    "vid_vc = vc_df[vc_df['Name'] == vid]\n",
    "tid_df = vid_vc[vid_vc['ISO Time'].between(\n",
    "    vid_times.loc[tid, 'start_time_actual'],\n",
    "    vid_times.loc[tid, 'end_time_actual'],\n",
    "    inclusive='both'\n",
    ")].copy()\n",
    "kwh_0 = tid_df.dropna().iloc[0]['Energy used (kWh)']\n",
    "dist_0 = tid_df.dropna().iloc[0]['Distance driven (mi)']\n",
    "tid_df['Energy used (kWh)'] = tid_df['Energy used (kWh)'] - kwh_0\n",
    "tid_df['Distance driven (mi)'] = tid_df['Distance driven (mi)'] - dist_0\n",
    "\n",
    "# Create figure with secondary y-axis\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Add traces\n",
    "secondary = [False, True]\n",
    "names = ['Energy', 'Distance']\n",
    "for ix, plot_col in enumerate(['Energy used (kWh)', 'Distance driven (mi)']):\n",
    "    fig.add_trace(go.Scatter(x=tid_df['ISO Time'], y=tid_df[plot_col], name=names[ix], mode='markers'), secondary_y=secondary[ix])\n",
    "\n",
    "# Add figure title\n",
    "fig.update_layout(\n",
    "    title_text=f'Bus {vid}, Trip {tid} on 3/15/24'\n",
    ")\n",
    "\n",
    "# Set x-axis title\n",
    "fig.update_xaxes(title_text='Time')\n",
    "\n",
    "# Set y-axes titles\n",
    "fig.update_yaxes(title_text='Energy used (kWh)', secondary_y=False)\n",
    "fig.update_yaxes(title_text='Distance driven (mi)', secondary_y=True)\n",
    "\n",
    "fig.write_image('images/chargepoint_trip_example.pdf')\n",
    "fig.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63668006-10e3-4f75-9234-73676672c41b",
   "metadata": {},
   "source": [
    "tid_df['Energy used (kWh)'].iloc[-1], tid_df['Distance driven (mi)'].iloc[-1], tid_df['Energy used (kWh)'].iloc[-1] / tid_df['Distance driven (mi)'].iloc[-1]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "57275049-a6ec-4ffa-b96e-5597a704615f",
   "metadata": {},
   "source": [
    "# Combine the energy and realtime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f1cb288b-4f26-46a6-8e0b-23a94d3e1b80",
   "metadata": {},
   "source": [
    "cleaned_trip_data = rt_trip_summary[\n",
    "    ['date', 'vehicle_id', 'trip_id', 'duration_sched', 'duration_rt', 'time_difference_pct']\n",
    "].merge(\n",
    "    vc_by_trip[\n",
    "        ['date', 'vehicle_id', 'trip_id', 'kwh', 'miles', 'kwh_per_mi']\n",
    "    ],\n",
    "    on=['date', 'vehicle_id', 'trip_id']\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d9bb644-0253-463e-a9c3-ec29b4182d96",
   "metadata": {},
   "source": [
    "cleaned_trip_data[cleaned_trip_data['time_difference_pct'] >= 0.4*cleaned_trip_data['time_difference_pct'].max()]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68badd70-5221-4faf-9f3b-4cfecce6b5de",
   "metadata": {},
   "source": [
    "# Throw out the above trips with questionable data\n",
    "cleaned_trip_data = cleaned_trip_data[\n",
    "    cleaned_trip_data['time_difference_pct'] < 0.4*cleaned_trip_data['time_difference_pct'].max()]\n",
    "cleaned_trip_data['vehicle_type'] = cleaned_trip_data['vehicle_id'].str[:2].map({'47': '40-foot', '48': '60-foot'})"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3d31859c-5897-4255-a6f9-4aa27d19a911",
   "metadata": {},
   "source": [
    "# Clean up and save the data for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9433f67a-ef19-4a84-9869-3344c2bd8f95",
   "metadata": {},
   "source": [
    "# Add route info and timing info\n",
    "data_out = cleaned_trip_data.merge(\n",
    "    trips_df[['trip_id', 'route_id', 'direction_id']], on='trip_id').merge(\n",
    "    routes_df[['route_id', 'route_short_name']]).drop(\n",
    "    columns=['route_id']).merge(\n",
    "        rt_trip_summary[['date', 'vehicle_id', 'trip_id', 'start_time_actual', 'end_time_actual']], on=['date', 'vehicle_id', 'trip_id']\n",
    ").rename(\n",
    "        columns={\n",
    "            'time_difference_pct': 'duration_difference_pct',\n",
    "            'route_short_name': 'route',\n",
    "            'start_time_actual': 'start_time',\n",
    "            'end_time_actual': 'end_time'\n",
    "        }\n",
    ")\n",
    "# Reorder columns\n",
    "data_out = data_out[\n",
    "    ['date', 'vehicle_id', 'vehicle_type', 'trip_id', 'route', 'direction_id', 'start_time', 'end_time',\n",
    "     'duration_sched', 'duration_rt', 'duration_difference_pct', 'kwh', 'miles', 'kwh_per_mi']\n",
    "]\n",
    "data_out.to_csv('../beb_chargers/data/processed/cleaned_trip_data.csv', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc332f77-7e30-4b6c-a1d5-31a348a645ed",
   "metadata": {},
   "source": [
    "data_out['start_time'].dt.hour.hist()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8760b215-2f54-4d8a-abd7-c40c951d1998",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
